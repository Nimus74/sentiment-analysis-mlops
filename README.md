# Sentiment Analysis MLOps

Sistema focalizzato sull'analisi del sentiment con architettura orientata MLOps, che utilizza un modello Transformer come approccio principale e FastText come baseline addestrata nel progetto per confronto.


## ğŸ“‹ Overview

Questo progetto implementa un sistema di sentiment analysis che permette di:
- Classificare il sentiment in positivo, neutro, negativo
- Confrontare modelli Transformer e FastText
- Integrare componenti sperimentali di monitoring


## ğŸ—ï¸ Architettura

Il sistema Ã¨ composto da:
- **Data Pipeline**: Ingestion, preprocessing, validation e split riproducibili
- **Modelli**: Transformer basato su cardiffnlp/twitter-roberta-base-sentiment-latest come modello principale; FastText addestrato come baseline nel progetto per confronto
- **MLOps**: MLflow per experiment tracking, Evidently AI per monitoring sperimentale
- **API**: FastAPI per inferenza con selezione backend
- **Deploy**: Deploy su Hugging Face opzionale e sperimentale
- **CI/CD**: GitHub Actions con test automatici
- **Monitoring**: Componenti di monitoring sperimentali per data quality e drift
- **Retraining**: Retraining automatico opzionale e sperimentale per FastText


## Allineamento con la traccia della consegna

Sebbene la traccia della consegna menzioni l'uso di FastText, in questo progetto Ã¨ stato scelto un modello Transformer come soluzione primaria in quanto dimostra prestazioni superiori su testi brevi e rumorosi tipici dei social media. FastText Ã¨ incluso come baseline supervisionata, addestrata su dataset pubblici e utilizzata per confronto. Questa scelta progettuale Ã¨ intenzionale e documentata per motivi di accuratezza e completezza nell'analisi.


## Notebook Google Colab (Consegna)

Apri ed esegui il notebook direttamente in Google Colab:

- **Colab**: https://colab.research.google.com/github/Nimus74/sentiment-analysis-mlops/blob/main/notebooks/DELIVERY_colab_sentiment_analysis.ipynb
- **Repository**: https://github.com/Nimus74/sentiment-analysis-mlops

> Nota: in alternativa, il notebook puÃ² essere condiviso anche tramite Google Drive (modalitÃ  tipica di consegna).


## ğŸ› Demo e funzionalitÃ  opzionali (non richieste per la consegna)

Oltre al notebook di consegna, il repository include alcune componenti **opzionali** sviluppate per dimostrare un approccio MLOps end-to-end:

### Demo UI â€“ Analisi del Sentiment
Ãˆ disponibile una semplice interfaccia web (Gradio) per testare lâ€™inferenza dei modelli Transformer e FastText:

```bash
python app.py
```

Lâ€™applicazione sarÃ  disponibile allâ€™indirizzo:
http://127.0.0.1:7860

### Monitoring & Reporting (POC)
Il progetto include inoltre una dashboard di monitoring realizzata in Streamlit, con report generati tramite Evidently AI:

```bash
streamlit run src/monitoring/dashboard.py
```

La dashboard consente di visualizzare:
- Data Quality
- Data Drift
- Prediction Drift
- Performance del modello

> Nota: queste funzionalitÃ  sono **proof-of-concept** e non sono richieste ai fini della valutazione.
> La consegna ufficiale del progetto Ã¨ rappresentata dal notebook Google Colab indicato sopra.


## ğŸš€ Quick Start

### Installazione

```bash
# Clonare il repository
git clone https://github.com/Nimus74/sentiment-analysis-mlops.git
cd sentiment-analysis-mlops

# Creare ambiente virtuale
python -m venv venv
source venv/bin/activate  # Su Windows: venv\Scripts\activate

# Installare dipendenze
pip install -r requirements.txt

# Installare package in modalitÃ  sviluppo
pip install -e .
```

### Training Modelli

```bash
# Training Transformer
python src/training/train_transformer.py --config configs/config.yaml

# Training FastText
python src/training/train_fasttext.py --config configs/config.yaml
```

### Avviare API

```bash
# Con Docker
docker-compose up

# Oppure direttamente
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

### Uso API

```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={
        "text": "Questo prodotto Ã¨ fantastico!",
        "model_type": "transformer"  # o "fasttext"
    }
)
print(response.json())
```

## ğŸ“Š Metriche

- **Metrica principale**: Macro-F1 Score
- **Metriche secondarie**: Accuracy, Precision, Recall per classe, Confusion Matrix

## ğŸ“ Struttura Progetto

```
sentiment_analysis/
â”œâ”€â”€ data/              # Dataset e cache
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/         # Data pipeline
â”‚   â”œâ”€â”€ models/       # Modelli (Transformer, FastText)
â”‚   â”œâ”€â”€ evaluation/   # Metriche e valutazione
â”‚   â”œâ”€â”€ api/          # API FastAPI
â”‚   â”œâ”€â”€ monitoring/   # Evidently AI reports
â”‚   â””â”€â”€ training/     # Script training e retraining
â”œâ”€â”€ tests/            # Test unitari e integrazione
â”œâ”€â”€ notebooks/        # Notebook analisi
â”œâ”€â”€ configs/          # File configurazione YAML
â”œâ”€â”€ docs/             # Documentazione
â””â”€â”€ .github/workflows/ # CI/CD pipelines
```


## ğŸ“š Documentazione

La documentazione presente nella cartella `docs/` include materiali di supporto e approfondimento
sviluppati durante il progetto, alcuni dei quali in forma di proof-of-concept o documentazione tecnica
di lavoro.

I file principali includono:
- [Guida POC Test Live](docs/POC_TEST_LIVE.md) â€“ guida operativa passo-passo allâ€™esecuzione del progetto
- [Architettura](docs/ARCHITECTURE.md)
- [Modelli](docs/MODELS.md)
- [Deploy](docs/DEPLOYMENT.md)
- [Monitoring](docs/MONITORING.md)

> Nota: parte della documentazione ha carattere **sperimentale o tecnico-interno** ed Ã¨ fornita
> a supporto della comprensione del progetto.


## ğŸ§ª Testing

```bash
# Eseguire tutti i test
pytest

# Con coverage
pytest --cov=src --cov-report=html
```

## ğŸ“ Stato del progetto / Limitazioni

- CI e test automatici sono implementati e tutti i test sono superati con successo
- Componenti di monitoring sono implementati come proof-of-concept e non ancora integrati in un sistema di produzione completo
- Deploy su Hugging Face e retraining continuo non sono completamente automatizzati e rappresentano estensioni opzionali e sperimentali del progetto
