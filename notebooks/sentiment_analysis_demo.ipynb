{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis MLOps - Demo Completa\n",
        "\n",
        "Questo notebook dimostra l'intero sistema di sentiment analysis con confronto Transformer vs FastText.\n",
        "\n",
        "**Repository GitHub**: https://github.com/yourusername/sentiment-analysis-mlops\n",
        "\n",
        "**Hugging Face Space**: https://huggingface.co/spaces/yourusername/sentiment-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Ambiente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installa dipendenze\n",
        "%pip install -q transformers torch fasttext pandas scikit-learn mlflow evidently datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.data.download_dataset import download_dataset\n",
        "from src.data.preprocessing import preprocess_dataframe\n",
        "from src.data.validation import validate_dataset_quality\n",
        "from src.data.split import stratified_split\n",
        "from src.models.transformer_model import TransformerSentimentModel\n",
        "from src.models.fasttext_model import FastTextSentimentModel\n",
        "from src.evaluation.metrics import calculate_metrics, compare_models_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download e Preparazione Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "df = download_dataset(\n",
        "    dataset_name=\"cardiffnlp/tweet_sentiment_multilingual\",\n",
        "    language=\"it\",\n",
        "    cache_dir=\"../data/raw\"\n",
        ")\n",
        "\n",
        "print(f\"Dataset scaricato: {len(df)} campioni\")\n",
        "print(f\"Colonne: {df.columns.tolist()}\")\n",
        "print(f\"\\nDistribuzione classi:\")\n",
        "print(df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "df_processed = preprocess_dataframe(\n",
        "    df,\n",
        "    text_column=\"text\",\n",
        "    min_length=3,\n",
        "    max_length=512\n",
        ")\n",
        "\n",
        "print(f\"Dopo preprocessing: {len(df_processed)} campioni\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split train/val/test\n",
        "train_df, val_df, test_df, split_indices = stratified_split(\n",
        "    df_processed,\n",
        "    train_size=0.70,\n",
        "    val_size=0.15,\n",
        "    test_size=0.15,\n",
        "    random_seed=42\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_df)} campioni\")\n",
        "print(f\"Val: {len(val_df)} campioni\")\n",
        "print(f\"Test: {len(test_df)} campioni\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training e Valutazione Modelli\n",
        "\n",
        "### 3.1 Transformer (Pre-addestrato)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carica modello Transformer pre-addestrato\n",
        "transformer = TransformerSentimentModel(\n",
        "    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        ")\n",
        "\n",
        "print(\"✅ Transformer caricato\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 FastText\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepara formato FastText\n",
        "from src.data.preprocessing import prepare_fasttext_format\n",
        "\n",
        "os.makedirs(\"../data/processed\", exist_ok=True)\n",
        "train_file = \"../data/processed/fasttext_train.txt\"\n",
        "prepare_fasttext_format(\n",
        "    train_df[\"text\"].tolist(),\n",
        "    train_df[\"label\"].tolist(),\n",
        "    train_file\n",
        ")\n",
        "\n",
        "# Training FastText\n",
        "os.makedirs(\"../models/fasttext\", exist_ok=True)\n",
        "fasttext_model = FastTextSentimentModel.train(\n",
        "    train_file=train_file,\n",
        "    output_path=\"../models/fasttext/fasttext_model.bin\",\n",
        "    epoch=25,\n",
        "    lr=0.1\n",
        ")\n",
        "\n",
        "print(\"✅ FastText addestrato\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Valutazione e Confronto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valutazione su test set\n",
        "test_texts = test_df[\"text\"].tolist()\n",
        "test_labels = test_df[\"label\"].tolist()\n",
        "\n",
        "unique_labels = sorted(test_df[\"label\"].unique())\n",
        "label_to_num = {label: i for i, label in enumerate(unique_labels)}\n",
        "\n",
        "# Transformer\n",
        "transformer_preds = transformer.predict_labels(test_texts)\n",
        "transformer_metrics = calculate_metrics(\n",
        "    np.array([label_to_num[l] for l in test_labels]),\n",
        "    transformer_preds,\n",
        "    labels=unique_labels\n",
        ")\n",
        "\n",
        "print(\"Transformer Metrics:\")\n",
        "print(f\"  Macro-F1: {transformer_metrics['macro_f1']:.4f}\")\n",
        "print(f\"  Accuracy: {transformer_metrics['accuracy']:.4f}\")\n",
        "\n",
        "# FastText\n",
        "fasttext_preds = fasttext_model.predict_labels(test_texts)\n",
        "fasttext_metrics = calculate_metrics(\n",
        "    np.array([label_to_num[l] for l in test_labels]),\n",
        "    fasttext_preds,\n",
        "    labels=unique_labels\n",
        ")\n",
        "\n",
        "print(\"\\nFastText Metrics:\")\n",
        "print(f\"  Macro-F1: {fasttext_metrics['macro_f1']:.4f}\")\n",
        "print(f\"  Accuracy: {fasttext_metrics['accuracy']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confronto modelli\n",
        "comparison = compare_models_metrics(\n",
        "    transformer_metrics,\n",
        "    fasttext_metrics,\n",
        "    \"Transformer\",\n",
        "    \"FastText\"\n",
        ")\n",
        "\n",
        "print(\"\\nConfronto Modelli:\")\n",
        "print(comparison.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Esempi Inferenza\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esempi testi\n",
        "test_examples = [\n",
        "    \"Questo prodotto è fantastico! Lo consiglio a tutti.\",\n",
        "    \"Il servizio è stato ok, niente di speciale.\",\n",
        "    \"Terribile esperienza, non lo consiglio affatto.\"\n",
        "]\n",
        "\n",
        "print(\"Esempi Inferenza:\\n\")\n",
        "for text in test_examples:\n",
        "    print(f\"Testo: {text}\")\n",
        "    \n",
        "    # Transformer\n",
        "    trans_result = transformer.predict(text)\n",
        "    print(f\"  Transformer: {trans_result['label']} (confidence: {trans_result['score']:.2f})\")\n",
        "    \n",
        "    # FastText\n",
        "    ft_result = fasttext_model.predict(text)\n",
        "    print(f\"  FastText: {ft_result['label']} (confidence: {ft_result['score']:.2f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualizzazioni\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm_transformer = confusion_matrix(\n",
        "    [label_to_num[l] for l in test_labels],\n",
        "    transformer_preds\n",
        ")\n",
        "\n",
        "cm_fasttext = confusion_matrix(\n",
        "    [label_to_num[l] for l in test_labels],\n",
        "    fasttext_preds\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(cm_transformer, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0],\n",
        "            xticklabels=unique_labels, yticklabels=unique_labels)\n",
        "axes[0].set_title(\"Transformer\")\n",
        "axes[0].set_ylabel(\"True Label\")\n",
        "axes[0].set_xlabel(\"Predicted Label\")\n",
        "\n",
        "sns.heatmap(cm_fasttext, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1],\n",
        "            xticklabels=unique_labels, yticklabels=unique_labels)\n",
        "axes[1].set_title(\"FastText\")\n",
        "axes[1].set_ylabel(\"True Label\")\n",
        "axes[1].set_xlabel(\"Predicted Label\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusioni\n",
        "\n",
        "Il sistema dimostra:\n",
        "- ✅ Pipeline dati completa e riproducibile\n",
        "- ✅ Confronto equo tra Transformer e FastText\n",
        "- ✅ Metriche standardizzate e tracciabili\n",
        "- ✅ Inferenza funzionante per entrambi i modelli\n",
        "\n",
        "**Prossimi passi**:\n",
        "- Deploy su Hugging Face Spaces\n",
        "- Setup monitoring con Evidently AI\n",
        "- Implementazione retraining automatico\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
