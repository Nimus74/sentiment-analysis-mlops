{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhtqRbgBhUfB"
   },
   "source": [
    "# Sentiment Analysis MLOps ‚Äì (Google Colab)\n",
    "\n",
    "Questo notebook accompagna il progetto di **Sentiment Analysis** sviluppato con un approccio **MLOps**, mostrando l‚Äôintero flusso:\n",
    "dalla preparazione dei dati alla valutazione dei modelli.\n",
    "\n",
    "- **Modello principale**: Transformer pre-addestrato  \n",
    "  `cardiffnlp/twitter-roberta-base-sentiment-latest`\n",
    "- **Baseline di confronto**: modello **FastText**, addestrato specificamente sul dataset del progetto\n",
    "- **Obiettivo**: dimostrare una pipeline completa, riproducibile e confrontabile per l‚Äôanalisi del sentiment\n",
    "\n",
    "üìå **Repository GitHub**  \n",
    "https://github.com/Nimus74/sentiment-analysis-mlops\n",
    "\n",
    "‚ÑπÔ∏è Il deploy su **Hugging Face Spaces** √® considerato un‚Äôestensione opzionale del progetto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAJzHrZGhUfD"
   },
   "source": [
    "## 1. Setup Ambiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dgex9ah23qwR"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"datasets<4.0.0\"\n",
    "\n",
    "# Clone repository\n",
    "%cd /content\n",
    "!rm -rf sentiment-analysis-mlops\n",
    "!git clone https://github.com/Nimus74/sentiment-analysis-mlops.git\n",
    "%cd sentiment-analysis-mlops\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt -q\n",
    "!pip install -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUm315kmhUfE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data.download_dataset import download_dataset\n",
    "from src.data.preprocessing import preprocess_dataframe\n",
    "from src.data.validation import validate_dataset_quality\n",
    "from src.data.split import stratified_split\n",
    "from src.models.transformer_model import TransformerSentimentModel\n",
    "from src.models.fasttext_model import FastTextSentimentModel\n",
    "from src.evaluation.metrics import calculate_metrics, compare_models_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tou3zYE3hUfF"
   },
   "source": [
    "## Confronto tra modelli\n",
    "\n",
    "Il modello Transformer √® utilizzato come approccio principale per l‚Äôanalisi del sentiment,\n",
    "mentre FastText √® impiegato come baseline supervisionata per confronto.\n",
    "\n",
    "Questa scelta √® motivata dalle migliori prestazioni dei modelli Transformer\n",
    "su testi brevi e rumorosi come quelli dei social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVjhyVYxhUfF"
   },
   "source": [
    "## 2. Download e Preparazione Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEh6AJ0_hUfG"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Download dataset (Hugging Face datasets)\n",
    "# Nota: questo dataset richiede un \"config name\" (es. 'all', 'italian', 'english', ecc.)\n",
    "dataset = load_dataset(\n",
    "    \"cardiffnlp/tweet_sentiment_multilingual\",\n",
    "    \"all\",\n",
    "    cache_dir=\"data/raw\"\n",
    ")\n",
    "\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "print(f\"Dataset scaricato: {len(df)} campioni\")\n",
    "print(f\"Colonne: {df.columns.tolist()}\")\n",
    "print(\"\\nDistribuzione classi:\")\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hd4xWRJZhUfG"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_processed = preprocess_dataframe(\n",
    "    df,\n",
    "    text_column=\"text\",\n",
    "    min_length=3,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "print(f\"Dopo preprocessing: {len(df_processed)} campioni\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pmr415KJhUfH"
   },
   "outputs": [],
   "source": [
    "# Split train/val/test\n",
    "train_df, val_df, test_df, split_indices = stratified_split(\n",
    "    df_processed,\n",
    "    train_size=0.70,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)} campioni\")\n",
    "print(f\"Val: {len(val_df)} campioni\")\n",
    "print(f\"Test: {len(test_df)} campioni\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3JCMK_zhUfH"
   },
   "source": [
    "## 3. Training e Valutazione Modelli\n",
    "\n",
    "### 3.1 Transformer (Pre-addestrato)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zt38jF97hUfI"
   },
   "outputs": [],
   "source": [
    "# Carica modello Transformer pre-addestrato\n",
    "transformer = TransformerSentimentModel(\n",
    "    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Transformer caricato\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P89EfJshUfI"
   },
   "source": [
    "### 3.2 FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQN10WWPhUfI"
   },
   "outputs": [],
   "source": [
    "# Prepara formato FastText\n",
    "from src.data.preprocessing import prepare_fasttext_format\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "train_file = \"data/processed/fasttext_train.txt\"\n",
    "prepare_fasttext_format(\n",
    "    train_df[\"text\"].tolist(),\n",
    "    train_df[\"label\"].tolist(),\n",
    "    train_file\n",
    ")\n",
    "\n",
    "# Training FastText\n",
    "os.makedirs(\"models/fasttext\", exist_ok=True)\n",
    "fasttext_model = FastTextSentimentModel.train(\n",
    "    train_file=train_file,\n",
    "    output_path=\"models/fasttext/fasttext_model.bin\",\n",
    "    epoch=25,\n",
    "    lr=0.1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ FastText addestrato\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dk2AOM8xhUfI"
   },
   "source": [
    "## 4. Valutazione e Confronto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pmu5Xgy9hUfI"
   },
   "outputs": [],
   "source": [
    "# Valutazione su test set\n",
    "test_texts = test_df[\"text\"].tolist()\n",
    "test_labels = test_df[\"label\"].tolist()\n",
    "\n",
    "unique_labels = sorted(test_df[\"label\"].unique())\n",
    "label_to_num = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Transformer\n",
    "transformer_preds = transformer.predict_labels(test_texts)\n",
    "transformer_metrics = calculate_metrics(\n",
    "    np.array([label_to_num[l] for l in test_labels]),\n",
    "    transformer_preds,\n",
    "    labels=unique_labels\n",
    ")\n",
    "\n",
    "print(\"Transformer Metrics:\")\n",
    "print(f\"  Macro-F1: {transformer_metrics['macro_f1']:.4f}\")\n",
    "print(f\"  Accuracy: {transformer_metrics['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvTmh4E95Hjx"
   },
   "source": [
    "### Nota sulle etichette FastText\n",
    "FastText produce etichette numeriche (`0/1/2`) in base al dataset di training.\n",
    "Per questo motivo, nel notebook la conversione viene gestita direttamente prima del calcolo delle metriche,\n",
    "mantenendo lo stesso spazio di label utilizzato in fase di split e valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pcnWTsboYu3"
   },
   "outputs": [],
   "source": [
    "# FastText - predictions (raw) + conversione numerica robusta\n",
    "preds = fasttext_model.predict_batch(test_texts)\n",
    "\n",
    "fasttext_preds = np.array([int(str(p[\"label\"]).replace(\"__label__\", \"\").strip()) for p in preds])\n",
    "\n",
    "fasttext_metrics = calculate_metrics(\n",
    "    np.array([label_to_num[l] for l in test_labels]),\n",
    "    fasttext_preds,\n",
    "    labels=unique_labels\n",
    ")\n",
    "\n",
    "print(\"\\nFastText Metrics:\")\n",
    "print(f\"  Macro-F1: {fasttext_metrics['macro_f1']:.4f}\")\n",
    "print(f\"  Accuracy: {fasttext_metrics['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97AVVFEBhUfI"
   },
   "outputs": [],
   "source": [
    "# Confronto modelli\n",
    "comparison = compare_models_metrics(\n",
    "    transformer_metrics,\n",
    "    fasttext_metrics,\n",
    "    \"Transformer\",\n",
    "    \"FastText\"\n",
    ")\n",
    "\n",
    "print(\"\\nConfronto Modelli:\")\n",
    "print(comparison.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSObNObQhUfJ"
   },
   "source": [
    "## 5. Esempi Inferenza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vJr6KBIhUfJ"
   },
   "outputs": [],
   "source": [
    "# Esempi testi\n",
    "test_examples = [\n",
    "    \"Questo prodotto √® fantastico! Lo consiglio a tutti.\",\n",
    "    \"Il servizio √® stato ok, niente di speciale.\",\n",
    "    \"Terribile esperienza, non lo consiglio affatto.\"\n",
    "]\n",
    "\n",
    "print(\"Esempi Inferenza:\\n\")\n",
    "for text in test_examples:\n",
    "    print(f\"Testo: {text}\")\n",
    "\n",
    "    # Transformer\n",
    "    trans_result = transformer.predict(text)\n",
    "    print(f\"  Transformer: {trans_result['label']} (confidence: {trans_result['score']:.2f})\")\n",
    "\n",
    "    # FastText\n",
    "    ft_result = fasttext_model.predict(text)[0]\n",
    "    print(f\"  FastText: {ft_result['label']} (confidence: {ft_result['score']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troBpzkJhUfJ"
   },
   "source": [
    "## 6. Visualizzazioni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lmEcT1thUfJ"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_transformer = confusion_matrix(\n",
    "    [label_to_num[l] for l in test_labels],\n",
    "    transformer_preds\n",
    ")\n",
    "\n",
    "cm_fasttext = confusion_matrix(\n",
    "    [label_to_num[l] for l in test_labels],\n",
    "    fasttext_preds\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(cm_transformer, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0],\n",
    "            xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "axes[0].set_title(\"Transformer\")\n",
    "axes[0].set_ylabel(\"True Label\")\n",
    "axes[0].set_xlabel(\"Predicted Label\")\n",
    "\n",
    "sns.heatmap(cm_fasttext, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1],\n",
    "            xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "axes[1].set_title(\"FastText\")\n",
    "axes[1].set_ylabel(\"True Label\")\n",
    "axes[1].set_xlabel(\"Predicted Label\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCJmdT3GhUfJ"
   },
   "source": [
    "## Conclusioni\n",
    "\n",
    "Il progetto ha portato alla realizzazione di una pipeline completa di **Sentiment Analysis end-to-end**, coprendo tutte le fasi richieste dalla consegna:\n",
    "\n",
    "- ‚úÖ Pipeline dati completa, riproducibile e modulare\n",
    "- ‚úÖ Implementazione e confronto tra due approcci distinti:\n",
    "  - **Transformer** pre-addestrato per sentiment analysis\n",
    "  - **FastText** addestrato specificamente sul dataset di progetto\n",
    "- ‚úÖ Valutazione oggettiva tramite metriche standard (Accuracy, F1, Precision, Recall)\n",
    "- ‚úÖ Inferenza funzionante e confrontabile per entrambi i modelli\n",
    "- ‚úÖ Visualizzazione dei risultati tramite confusion matrix\n",
    "\n",
    "Dal confronto emerge come, in questo scenario specifico, **FastText ottenga prestazioni migliori in termini di Macro-F1**, evidenziando come modelli pi√π leggeri ma addestrati su dati coerenti possano risultare competitivi rispetto a modelli pi√π complessi.\n",
    "\n",
    "### Prossimi passi\n",
    "- Deploy dell‚Äôapplicazione su **Hugging Face Spaces**\n",
    "- Integrazione di un sistema di **monitoring continuo** con Evidently AI\n",
    "- Automazione del **retraining del modello** all‚Äôarrivo di nuovi dati\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
